{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with Keras\n",
    "\n",
    "Code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.applications import inception_v3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of pathnames with associated labels based on folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_list(img_dir):\n",
    "    folders = os.listdir(img_dir)\n",
    "    folders.sort()\n",
    "    indexes = range(len(folders))\n",
    "    label_map = {key: value for (key, value) in zip(folders, indexes)}\n",
    "        \n",
    "    labeled_image_list = [(os.path.join(img_dir, folder, image), label_map[folder]) \n",
    "                          for folder in folders \n",
    "                          for image in os.listdir(os.path.join(img_dir, folder))\n",
    "                         ]\n",
    "    return zip(*labeled_image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image generator to feed Keras `Model.predict_generator()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, image_list, preprocess_fn=None, batch_size=64):\n",
    "        self.image_list = image_list \n",
    "        #self.label_list = label_list\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pathnames = self.image_list[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        images = self.__load_images(pathnames)\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    def __load_images(self, pathnames):\n",
    "        images = []\n",
    "        for pathname in pathnames:\n",
    "            img = image.load_img(pathname, target_size=(224,224,3))\n",
    "            img = image.img_to_array(img)\n",
    "            images.append(img)\n",
    "        images = np.asarray(images)\n",
    "        if self.preprocess_fn != None:\n",
    "            images = self.preprocess_fn(images)   \n",
    "        \n",
    "        return images\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image featurizer based on ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetFeaturizer():\n",
    "    def __init__(self):\n",
    "        self.base_model = resnet50.ResNet50(\n",
    "            weights = 'imagenet', \n",
    "            input_shape=(224,224,3), \n",
    "            include_top = False,\n",
    "            pooling = 'avg')\n",
    "        \n",
    "    def extract(self, image_list):\n",
    "        image_generator = ImageGenerator(image_list, resnet50.preprocess_input)\n",
    "        features = self.base_model.predict_generator(image_generator, verbose=1)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that configures TF dataset on top of Numpy tensors with images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dataset based on a list of TFRecords files passsed as a parameters. \n",
    "def create_dataset(data, labels, batch_size, train=True, buffer_size=10000):\n",
    "    \n",
    "  labels = tf.one_hot(labels, 6)  \n",
    "  dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "  if train:\n",
    "    dataset = dataset.shuffle(buffer_size)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.repeat()\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a small FCN to layer on top of featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(input_shape=(2048,), units=512, classes=6,  l1=0.01, l2=0.01):\n",
    "    features = Input(shape=input_shape)\n",
    "    x = Dense(units, activation='relu')(features)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(classes, activation='softmax', kernel_regularizer=l1_l2(l1=l1, l2=l2))(x)\n",
    "    model = Model(inputs=features, outputs=y)\n",
    "    model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and validation datasets\n",
    "\n",
    "The images should be in a folder structure under `img_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '../../../Datasets/aerialimages/train'\n",
    "\n",
    "img_list, label_list = create_image_list(img_dir)\n",
    "\n",
    "train_imgs, valid_imgs, \\\n",
    "train_labels, valid_labels = train_test_split(img_list, label_list,\n",
    "                                           test_size=0.15,\n",
    "                                           random_state=0,\n",
    "                                           stratify=label_list)\n",
    "\n",
    "featurizer = ResNetFeaturizer()\n",
    "    \n",
    "train_features = featurizer.extract(train_imgs)\n",
    "valid_features = featurizer.extract(valid_imgs)\n",
    "train_labels = train_labels[0:len(train_features)]\n",
    "valid_labels = train_labels[0:len(valid_features)]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up and start training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = classifier(input_shape=(2048,), units=1024, l1=0.006, l2=0.006)\n",
    "model.summary()\n",
    "\n",
    "batch_size = 64\n",
    "steps_per_epoch = len(train_features)//batch_size\n",
    "validation_steps = len(valid_features)//batch_size\n",
    "\n",
    "train_dataset = create_dataset(train_features, train_labels, batch_size=batch_size, train=True)\n",
    "valid_dataset = create_dataset(valid_features, valid_labels, batch_size=batch_size, train=False)\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          epochs=100,\n",
    "          steps_per_epoch = steps_per_epoch,\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps = validation_steps\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dataset based on a list of TFRecords files passsed as a parameters. \n",
    "def create_dataset(files, batch_size, train=True, buffer_size=10000):\n",
    "  IMAGE_SHAPE = (224, 224, 3,)\n",
    "  NUM_CLASSES = 6\n",
    "    \n",
    "  def scale_image(image):\n",
    "      image = image / 127.5\n",
    "      image = image - 1.\n",
    "      return image\n",
    "    \n",
    "  def _parse(example_proto):\n",
    "    features = {'label': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "                'image': tf.FixedLenFeature((), tf.string, default_value=\"\")}\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    label = parsed_features['label']\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    image = image = tf.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = scale_image(image)\n",
    "    image = tf.reshape(image, IMAGE_SHAPE)\n",
    "    return image, label\n",
    "  \n",
    "  dataset = tf.data.TFRecordDataset(files)\n",
    "  dataset = dataset.map(_parse)\n",
    "  if train:\n",
    "    dataset = dataset.shuffle(buffer_size)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.repeat()\n",
    "  return dataset\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
