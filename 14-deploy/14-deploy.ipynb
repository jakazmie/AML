{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Model operationalization\n",
    "\n",
    "In the previous part of the lab, we run a series of training runs and registered the best performing version of the model in Model Registry.\n",
    "\n",
    "Now, we are ready to deploy the model.\n",
    "\n",
    "The model can be deployed to a variety of target runtimes, including:\n",
    "- Azure Container Instance\n",
    "- Azure Kubernetes Service\n",
    "- IoT Edge\n",
    "- FPGA\n",
    "\n",
    "\n",
    "In this lab, we will deploy the model as a web service in Azure Container Instance.\n",
    "\n",
    "![AML Arch](../images/amlarch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/demouser/repos/AML/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the model\n",
    "The model is registered in the workspace's Model Registry. First, download the model to your local directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "os.stat_result(st_mode=33204, st_ino=2310805, st_dev=2049, st_nlink=1, st_uid=1000, st_gid=1000, st_size=3210976, st_atime=1540354507, st_mtime=1540354508, st_ctime=1540354508)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "import os\n",
    "\n",
    "model=Model(ws, 'aerial_keras')\n",
    "model.download(target_dir = '.')\n",
    " \n",
    "# verify the downloaded model file\n",
    "os.stat('./aerial_keras.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy as web service\n",
    "\n",
    "To build the correct environment for ACI, provide the following:\n",
    "* A scoring script that invokes the model\n",
    "* An environment file to show what packages need to be installed\n",
    "* A configuration file to build the ACI\n",
    "* The model you trained before\n",
    "\n",
    "### Create scoring script\n",
    "\n",
    "Create the scoring script, called score.py, used by the web service call to invoke the model.\n",
    "\n",
    "You must include two required functions in the scoring script:\n",
    "* The `init()` function, which loads the model into a global object. This function is run only once when the Docker container is started. \n",
    "\n",
    "* The `run(input_data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats can be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import random\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    # Instantiate VGG16 featurizer\n",
    "    global featurizer\n",
    "    featurizer = vgg16.VGG16(\n",
    "            weights = 'imagenet', \n",
    "            input_shape=(224,224,3), \n",
    "            include_top = False,\n",
    "            pooling = 'avg')\n",
    "\n",
    "    # Load the model\n",
    "    global model\n",
    "    # retreive the path to the model file using the model name\n",
    "    model_path = Model.get_model_path('aerial_keras')\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    # convert json to numpy array\n",
    "    img = np.array(json.loads(raw_data)['data'])\n",
    "    # normalize as required by ResNet50\n",
    "    img = vgg16.preprocess_input(img)\n",
    "    # extract bottleneck features\n",
    "    features = featurizer.predict(img)\n",
    "    # make prediction\n",
    "    predictions = model.predict(features)\n",
    "    return json.dumps(predictions.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create environment file\n",
    "Next, create an environment file, called myenv.yml, that specifies all of the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. This model needs `tensorflow`, `h5py` and `azureml-sdk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_pip_package(\"tensorflow\")\n",
    "myenv.add_pip_package(\"h5py\")\n",
    "myenv.add_pip_package(\"pynacl==1.2.1\")\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the content of `myenv.yml` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "  - tensorflow\n",
      "  - h5py\n",
      "  - pynacl==1.2.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"myenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create configuration file\n",
    "\n",
    "Create a deployment configuration file and specify the number of CPUs and gigabyte of RAM needed for your ACI container. The default is 1 core and 1 gigabyte of RAM. Since we are using ResNet50 featurizer we are CPU bound.  In this lab we will use the defaults but you should always go through the proper performance plannig exercise to find the right configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"aerial\",  \"method\" : \"classifier\"}, \n",
    "                                               description='Predict aerial images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy in ACI\n",
    "Estimated time to complete: **about 7-8 minutes**\n",
    "\n",
    "Configure the image and deploy. The following code goes through these steps:\n",
    "\n",
    "1. Build an image using:\n",
    "   * The scoring file (`score.py`)\n",
    "   * The environment file (`myenv.yml`)\n",
    "   * The model file\n",
    "1. Register that image under the workspace. \n",
    "1. Send the image to the ACI container.\n",
    "1. Start up a container in ACI using the image.\n",
    "1. Get the web service HTTP endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Image creation operation finished for image aerial-classifier-svc:1, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running....................................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "CPU times: user 1.69 s, sys: 76.4 ms, total: 1.76 s\n",
      "Wall time: 8min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "# configure the image\n",
    "image_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n",
    "                                                  runtime=\"python\", \n",
    "                                                  conda_file=\"myenv.yml\")\n",
    "\n",
    "service = Webservice.deploy_from_model(workspace=ws,\n",
    "                                       name='aerial-classifier-svc',\n",
    "                                       deployment_config=aciconfig,\n",
    "                                       models=[model],\n",
    "                                       image_config=image_config)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://168.62.180.78:80/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test deployed service\n",
    "\n",
    "You will now test the deployed model with 3 test images.  \n",
    "\n",
    "The following code goes through these steps:\n",
    "1. Send the data as a JSON array to the web service hosted in ACI. \n",
    "\n",
    "2. Use the SDK's `run` API to invoke the service. You can also make raw calls using any HTTP tool such as curl.\n",
    "\n",
    "3. Print the returned predictions \n",
    "\n",
    " \n",
    "First, download sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1008\n",
      "-rw-rw-r-- 1 demouser demouser 91989 Oct 23 19:20 barren-1.png\n",
      "-rw-rw-r-- 1 demouser demouser 91989 Oct 23 19:20 barren-1.png.1\n",
      "-rw-rw-r-- 1 demouser demouser 91989 Oct 23 19:20 barren-1.png.2\n",
      "-rw-rw-r-- 1 demouser demouser 91989 Oct 23 19:20 barren-1.png.3\n",
      "-rw-rw-r-- 1 demouser demouser 66363 Oct 23 19:20 cultivated-1.png\n",
      "-rw-rw-r-- 1 demouser demouser 66363 Oct 23 19:20 cultivated-1.png.1\n",
      "-rw-rw-r-- 1 demouser demouser 66363 Oct 23 19:20 cultivated-1.png.2\n",
      "-rw-rw-r-- 1 demouser demouser 66363 Oct 23 19:20 cultivated-1.png.3\n",
      "-rw-rw-r-- 1 demouser demouser 92096 Oct 23 19:20 developed-1.png\n",
      "-rw-rw-r-- 1 demouser demouser 92096 Oct 23 19:20 developed-1.png.1\n",
      "-rw-rw-r-- 1 demouser demouser 92096 Oct 23 19:20 developed-1.png.2\n",
      "-rw-rw-r-- 1 demouser demouser 92096 Oct 23 19:20 developed-1.png.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘samples’: File exists\n",
      "2018-10-24 04:33:48 URL:https://azureailabs.blob.core.windows.net/aerialsamples/barren-1.png [91989/91989] -> \"barren-1.png.3\" [1]\n",
      "2018-10-24 04:33:49 URL:https://azureailabs.blob.core.windows.net/aerialsamples/cultivated-1.png [66363/66363] -> \"cultivated-1.png.3\" [1]\n",
      "2018-10-24 04:33:49 URL:https://azureailabs.blob.core.windows.net/aerialsamples/developed-1.png [92096/92096] -> \"developed-1.png.3\" [1]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir samples\n",
    "cd samples\n",
    "wget -nv https://azureailabs.blob.core.windows.net/aerialsamples/barren-1.png\n",
    "wget -nv https://azureailabs.blob.core.windows.net/aerialsamples/cultivated-1.png\n",
    "wget -nv https://azureailabs.blob.core.windows.net/aerialsamples/developed-1.png\n",
    "ls -l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define utility function that wraps loading images and invoking the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def score(pathnames, service):\n",
    "    images = []\n",
    "    for pathname in pathnames:\n",
    "        img = Image.open(pathname)\n",
    "        img = np.asarray(img).tolist()\n",
    "        images.append(img)\n",
    "    images = json.dumps({\"data\": images})\n",
    "    images = bytes(images, encoding='utf8')\n",
    "    results = json.loads(service.run(input_data=images))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9246954917907715, 0.011579126119613647, 0.006325280759483576, 0.005089320708066225, 0.011693309992551804, 0.04061754420399666], [1.0658142146624527e-09, 4.551152699150407e-08, 1.0, 9.22089793409242e-10, 7.581519301247397e-10, 1.1478453482301719e-14], [0.00013694365043193102, 0.05383246764540672, 0.021550456061959267, 0.21777337789535522, 0.03038136474788189, 0.6763253211975098]]\n"
     ]
    }
   ],
   "source": [
    "pathnames = ['samples/barren-1.png', 'samples/developed-1.png', 'samples/cultivated-1.png']\n",
    "\n",
    "results = score(pathnames, service)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "To keep the resource group and workspace for other tutorials and exploration, you can delete only the ACI deployment using this API call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
